{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorchic_bert_usage.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgHXIXbLA5pu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "892aa5d5-5cb6-41c1-a7c2-eb7909a3f2d1"
      },
      "source": [
        "!pip install fire"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/b7/205702f348aab198baecd1d8344a90748cb68f53bdcd1cc30cbc08e47d3e/fire-0.1.3.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/1a/4d/6b30377c3051e76559d1185c1dbbfff15aed31f87acdd14c22\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoppnJlUBBOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "9aa9cdf6-baa1-486d-fa25-dd7402426d83"
      },
      "source": [
        "!git clone https://github.com/dhlee347/pytorchic-bert.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorchic-bert'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)   \u001b[K\rremote: Counting objects:  28% (2/7)   \u001b[K\rremote: Counting objects:  42% (3/7)   \u001b[K\rremote: Counting objects:  57% (4/7)   \u001b[K\rremote: Counting objects:  71% (5/7)   \u001b[K\rremote: Counting objects:  85% (6/7)   \u001b[K\rremote: Counting objects: 100% (7/7)   \u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  14% (1/7)   \u001b[K\rremote: Compressing objects:  28% (2/7)   \u001b[K\rremote: Compressing objects:  42% (3/7)   \u001b[K\rremote: Compressing objects:  57% (4/7)   \u001b[K\rremote: Compressing objects:  71% (5/7)   \u001b[K\rremote: Compressing objects:  85% (6/7)   \u001b[K\rremote: Compressing objects: 100% (7/7)   \u001b[K\rremote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "Receiving objects:   0% (1/169)   \rReceiving objects:   1% (2/169)   \rReceiving objects:   2% (4/169)   \rReceiving objects:   3% (6/169)   \rReceiving objects:   4% (7/169)   \rReceiving objects:   5% (9/169)   \rReceiving objects:   6% (11/169)   \rReceiving objects:   7% (12/169)   \rReceiving objects:   8% (14/169)   \rReceiving objects:   9% (16/169)   \rReceiving objects:  10% (17/169)   \rReceiving objects:  11% (19/169)   \rReceiving objects:  12% (21/169)   \rReceiving objects:  13% (22/169)   \rReceiving objects:  14% (24/169)   \rReceiving objects:  15% (26/169)   \rReceiving objects:  16% (28/169)   \rReceiving objects:  17% (29/169)   \rReceiving objects:  18% (31/169)   \rReceiving objects:  19% (33/169)   \rReceiving objects:  20% (34/169)   \rReceiving objects:  21% (36/169)   \rReceiving objects:  22% (38/169)   \rReceiving objects:  23% (39/169)   \rReceiving objects:  24% (41/169)   \rReceiving objects:  25% (43/169)   \rReceiving objects:  26% (44/169)   \rReceiving objects:  27% (46/169)   \rReceiving objects:  28% (48/169)   \rReceiving objects:  29% (50/169)   \rReceiving objects:  30% (51/169)   \rReceiving objects:  31% (53/169)   \rReceiving objects:  32% (55/169)   \rReceiving objects:  33% (56/169)   \rReceiving objects:  34% (58/169)   \rReceiving objects:  35% (60/169)   \rReceiving objects:  36% (61/169)   \rReceiving objects:  37% (63/169)   \rReceiving objects:  38% (65/169)   \rReceiving objects:  39% (66/169)   \rReceiving objects:  40% (68/169)   \rReceiving objects:  41% (70/169)   \rReceiving objects:  42% (71/169)   \rReceiving objects:  43% (73/169)   \rReceiving objects:  44% (75/169)   \rReceiving objects:  45% (77/169)   \rReceiving objects:  46% (78/169)   \rReceiving objects:  47% (80/169)   \rReceiving objects:  48% (82/169)   \rReceiving objects:  49% (83/169)   \rReceiving objects:  50% (85/169)   \rReceiving objects:  51% (87/169)   \rReceiving objects:  52% (88/169)   \rReceiving objects:  53% (90/169)   \rReceiving objects:  54% (92/169)   \rremote: Total 169 (delta 1), reused 0 (delta 0), pack-reused 162\u001b[K\n",
            "Receiving objects:  55% (93/169)   \rReceiving objects:  56% (95/169)   \rReceiving objects:  57% (97/169)   \rReceiving objects:  58% (99/169)   \rReceiving objects:  59% (100/169)   \rReceiving objects:  60% (102/169)   \rReceiving objects:  61% (104/169)   \rReceiving objects:  62% (105/169)   \rReceiving objects:  63% (107/169)   \rReceiving objects:  64% (109/169)   \rReceiving objects:  65% (110/169)   \rReceiving objects:  66% (112/169)   \rReceiving objects:  67% (114/169)   \rReceiving objects:  68% (115/169)   \rReceiving objects:  69% (117/169)   \rReceiving objects:  70% (119/169)   \rReceiving objects:  71% (120/169)   \rReceiving objects:  72% (122/169)   \rReceiving objects:  73% (124/169)   \rReceiving objects:  74% (126/169)   \rReceiving objects:  75% (127/169)   \rReceiving objects:  76% (129/169)   \rReceiving objects:  77% (131/169)   \rReceiving objects:  78% (132/169)   \rReceiving objects:  79% (134/169)   \rReceiving objects:  80% (136/169)   \rReceiving objects:  81% (137/169)   \rReceiving objects:  82% (139/169)   \rReceiving objects:  83% (141/169)   \rReceiving objects:  84% (142/169)   \rReceiving objects:  85% (144/169)   \rReceiving objects:  86% (146/169)   \rReceiving objects:  87% (148/169)   \rReceiving objects:  88% (149/169)   \rReceiving objects:  89% (151/169)   \rReceiving objects:  90% (153/169)   \rReceiving objects:  91% (154/169)   \rReceiving objects:  92% (156/169)   \rReceiving objects:  93% (158/169)   \rReceiving objects:  94% (159/169)   \rReceiving objects:  95% (161/169)   \rReceiving objects:  96% (163/169)   \rReceiving objects:  97% (164/169)   \rReceiving objects:  98% (166/169)   \rReceiving objects:  99% (168/169)   \rReceiving objects: 100% (169/169)   \rReceiving objects: 100% (169/169), 55.42 KiB | 2.41 MiB/s, done.\n",
            "Resolving deltas:   0% (0/94)   \rResolving deltas:   1% (1/94)   \rResolving deltas:   2% (2/94)   \rResolving deltas:   4% (4/94)   \rResolving deltas:   5% (5/94)   \rResolving deltas:   6% (6/94)   \rResolving deltas:   7% (7/94)   \rResolving deltas:   8% (8/94)   \rResolving deltas:  10% (10/94)   \rResolving deltas:  11% (11/94)   \rResolving deltas:  14% (14/94)   \rResolving deltas:  18% (17/94)   \rResolving deltas:  19% (18/94)   \rResolving deltas:  35% (33/94)   \rResolving deltas:  70% (66/94)   \rResolving deltas:  71% (67/94)   \rResolving deltas:  78% (74/94)   \rResolving deltas:  82% (78/94)   \rResolving deltas:  85% (80/94)   \rResolving deltas: 100% (94/94)   \rResolving deltas: 100% (94/94), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfSM3J1VBJaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp pytorchic-bert/*.py .\n",
        "!cp -r pytorchic-bert/config ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WngZkOvNBOvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "3e469160-4f37-4994-9619-e6ecb05d4162"
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-28 12:17:59--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.214.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   100MB/s    in 3.9s    \n",
            "\n",
            "2019-06-28 12:18:03 (100 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ka4rp8pBVZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7be8bab6-f21d-4c9f-9f24-91737f25b82a"
      },
      "source": [
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3Yae24cBXGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "057c8750-60cd-4a98-f2f1-b83b051bdac3"
      },
      "source": [
        "!mkdir mrpc\n",
        "!wget -O mrpc/train.tsv https://docs.google.com/uc?id='1m5ft6FSPB5ORy6CMu7612PK3gBD81Hm0'\n",
        "!wget -O mrpc/dev.tsv https://docs.google.com/uc?id='1oex3jntQ6LIfNi4LacKqBF15G71g2KeB'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-28 12:20:24--  https://docs.google.com/uc?id=1m5ft6FSPB5ORy6CMu7612PK3gBD81Hm0\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.111.113, 108.177.111.101, 108.177.111.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.111.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-6k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ql139oo12lri1fqblgtv4bcub9tvid6u/1561723200000/06007603302574522241/*/1m5ft6FSPB5ORy6CMu7612PK3gBD81Hm0 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2019-06-28 12:20:24--  https://doc-0s-6k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ql139oo12lri1fqblgtv4bcub9tvid6u/1561723200000/06007603302574522241/*/1m5ft6FSPB5ORy6CMu7612PK3gBD81Hm0\n",
            "Resolving doc-0s-6k-docs.googleusercontent.com (doc-0s-6k-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-0s-6k-docs.googleusercontent.com (doc-0s-6k-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 941471 (919K) [text/tab-separated-values]\n",
            "Saving to: ‘mrpc/train.tsv’\n",
            "\n",
            "mrpc/train.tsv      100%[===================>] 919.41K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2019-06-28 12:20:25 (118 MB/s) - ‘mrpc/train.tsv’ saved [941471/941471]\n",
            "\n",
            "--2019-06-28 12:20:26--  https://docs.google.com/uc?id=1oex3jntQ6LIfNi4LacKqBF15G71g2KeB\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.120.139, 108.177.120.102, 108.177.120.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.120.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-6k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1i5f57phdcd0oa5r5sjqujs19c1epmbl/1561723200000/06007603302574522241/*/1oex3jntQ6LIfNi4LacKqBF15G71g2KeB [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2019-06-28 12:20:27--  https://doc-0o-6k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1i5f57phdcd0oa5r5sjqujs19c1epmbl/1561723200000/06007603302574522241/*/1oex3jntQ6LIfNi4LacKqBF15G71g2KeB\n",
            "Resolving doc-0o-6k-docs.googleusercontent.com (doc-0o-6k-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-0o-6k-docs.googleusercontent.com (doc-0o-6k-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 105616 (103K) [text/tab-separated-values]\n",
            "Saving to: ‘mrpc/dev.tsv’\n",
            "\n",
            "mrpc/dev.tsv        100%[===================>] 103.14K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-06-28 12:20:27 (110 MB/s) - ‘mrpc/dev.tsv’ saved [105616/105616]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcZQoF-8B4VL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "69227931-bdb1-4667-e307-88e0f5e84cf7"
      },
      "source": [
        "!head mrpc/train.tsv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿Quality\t#1 ID\t#2 ID\t#1 String\t#2 String\n",
            "1\t702876\t702977\tAmrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .\tReferring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\n",
            "0\t2108705\t2108831\tYucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\tYucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\n",
            "1\t1330381\t1330521\tThey had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .\tOn June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\n",
            "0\t3344667\t3344648\tAround 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .\tTab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .\n",
            "1\t1236820\t1236712\tThe stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .\tPG & E Corp. shares jumped $ 1.63 or 8 percent to $ 21.03 on the New York Stock Exchange on Friday .\n",
            "1\t738533\t737951\tRevenue in the first quarter of the year dropped 15 percent from the same period a year earlier .\tWith the scandal hanging over Stewart 's company , revenue the first quarter of the year dropped 15 percent from the same period a year earlier .\n",
            "0\t264589\t264502\tThe Nasdaq had a weekly gain of 17.27 , or 1.2 percent , closing at 1,520.15 on Friday .\tThe tech-laced Nasdaq Composite .IXIC rallied 30.46 points , or 2.04 percent , to 1,520.15 .\n",
            "1\t579975\t579810\tThe DVD-CCA then appealed to the state Supreme Court .\tThe DVD CCA appealed that decision to the U.S. Supreme Court .\n",
            "0\t3114205\t3114194\tThat compared with $ 35.18 million , or 24 cents per share , in the year-ago period .\tEarnings were affected by a non-recurring $ 8 million tax benefit in the year-ago period .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL4OqygPB85e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "3d4b3a39-e94c-4393-d8e3-9c528cb9cc9d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint.py  optim.py\t\ttrain.py\n",
            "classify.py    pretrain.py\tuncased_L-12_H-768_A-12\n",
            "config\t       pytorchic-bert\tuncased_L-12_H-768_A-12.zip\n",
            "models.py      sample_data\tutils.py\n",
            "mrpc\t       tokenization.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi827cH2B_yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv, fire, itertools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import train, models, optim, tokenization, classify\n",
        "from utils import *\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqCPAj8vCS_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "94896b97-0cb6-4f0c-9a97-faecbb77ce46"
      },
      "source": [
        "cfg = train.Config.from_json('config/train_mrpc.json')\n",
        "model_cfg = models.Config.from_json('config/bert_base.json')\n",
        "print(cfg)\n",
        "print(model_cfg)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Config(seed=42, batch_size=32, lr=2e-05, n_epochs=3, warmup=0.1, save_steps=100, total_steps=345)\n",
            "Config(vocab_size=30522, dim=768, n_layers=12, n_heads=12, dim_ff=3072, p_drop_hidden=0.1, p_drop_attn=0.1, max_len=512, n_segments=2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfJhhNPCVDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len=128\n",
        "set_seeds(42)\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file='uncased_L-12_H-768_A-12/vocab.txt', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtwxd0VWCWwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "664a94f4-80f7-4ac9-e2e2-937548c5f240"
      },
      "source": [
        "!tail -n 1000 uncased_L-12_H-768_A-12/vocab.txt | head -n 10"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##ssee\n",
            "colossal\n",
            "foreigner\n",
            "vet\n",
            "freaks\n",
            "patrice\n",
            "rosewood\n",
            "triassic\n",
            "upstate\n",
            "##pkins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJMiHuS6CYwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = [classify.Tokenizing(tokenizer.convert_to_unicode, tokenizer.tokenize),\n",
        "                classify.AddSpecialTokensWithTruncation(max_len),\n",
        "                classify.TokenIndexing(tokenizer.convert_tokens_to_ids,\n",
        "                classify.MRPC.labels, max_len)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1y94t3QCacp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_instances(lines):\n",
        "    for line in itertools.islice(lines, 1, 3): # skip header\n",
        "        yield line[0], line[3], line[4] # label, text_a, text_b\n",
        "\n",
        "def get_dataset(file, pipeline):\n",
        "  data = []\n",
        "  with open('mrpc/dev.tsv', \"r\") as f:\n",
        "      # list of splitted lines : line is also list\n",
        "      lines = csv.reader(f, delimiter='\\t', quotechar=None)\n",
        "      for instance in get_instances(lines): # instance : tuple of fields\n",
        "          for proc in pipeline: # a bunch of pre-processing\n",
        "              instance = proc(instance)\n",
        "          data.append(instance)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNZXPG8NCc2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "54c985ed-bba9-49f3-c38c-b344d33076fe"
      },
      "source": [
        "  print(f\"\\n* Take a look at the dataset according to pipeline (max_len : {max_len}):\\n\")\n",
        "  for i in range(len(pipeline)+1):\n",
        "      print(\"Preprocessing Pipeline : \", end=\"\")\n",
        "      for proc in pipeline[:i]:\n",
        "          print(type(proc).__name__, end=\", \")\n",
        "      dataset =get_dataset('mrpc/dev.tsv',pipeline[:i])\n",
        "      print('\\n', dataset[0], '\\n', dataset[1], '\\n')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* Take a look at the dataset according to pipeline (max_len : 128):\n",
            "\n",
            "Preprocessing Pipeline : \n",
            " ('1', \"He said the foodservice pie business doesn 't fit the company 's long-term growth strategy .\", '\" The foodservice pie business does not fit our long-term growth strategy .') \n",
            " ('0', 'Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war .', 'His wife said he was \" 100 percent behind George Bush \" and looked forward to using his years of training in the war .') \n",
            "\n",
            "Preprocessing Pipeline : Tokenizing, \n",
            " ('1', ['he', 'said', 'the', 'foods', '##er', '##vic', '##e', 'pie', 'business', 'doesn', \"'\", 't', 'fit', 'the', 'company', \"'\", 's', 'long', '-', 'term', 'growth', 'strategy', '.'], ['\"', 'the', 'foods', '##er', '##vic', '##e', 'pie', 'business', 'does', 'not', 'fit', 'our', 'long', '-', 'term', 'growth', 'strategy', '.']) \n",
            " ('0', ['magna', '##relli', 'said', 'ra', '##cic', '##ot', 'hated', 'the', 'iraqi', 'regime', 'and', 'looked', 'forward', 'to', 'using', 'his', 'long', 'years', 'of', 'training', 'in', 'the', 'war', '.'], ['his', 'wife', 'said', 'he', 'was', '\"', '100', 'percent', 'behind', 'george', 'bush', '\"', 'and', 'looked', 'forward', 'to', 'using', 'his', 'years', 'of', 'training', 'in', 'the', 'war', '.']) \n",
            "\n",
            "Preprocessing Pipeline : Tokenizing, AddSpecialTokensWithTruncation, \n",
            " ('1', ['[CLS]', 'he', 'said', 'the', 'foods', '##er', '##vic', '##e', 'pie', 'business', 'doesn', \"'\", 't', 'fit', 'the', 'company', \"'\", 's', 'long', '-', 'term', 'growth', 'strategy', '.', '[SEP]'], ['\"', 'the', 'foods', '##er', '##vic', '##e', 'pie', 'business', 'does', 'not', 'fit', 'our', 'long', '-', 'term', 'growth', 'strategy', '.', '[SEP]']) \n",
            " ('0', ['[CLS]', 'magna', '##relli', 'said', 'ra', '##cic', '##ot', 'hated', 'the', 'iraqi', 'regime', 'and', 'looked', 'forward', 'to', 'using', 'his', 'long', 'years', 'of', 'training', 'in', 'the', 'war', '.', '[SEP]'], ['his', 'wife', 'said', 'he', 'was', '\"', '100', 'percent', 'behind', 'george', 'bush', '\"', 'and', 'looked', 'forward', 'to', 'using', 'his', 'years', 'of', 'training', 'in', 'the', 'war', '.', '[SEP]']) \n",
            "\n",
            "Preprocessing Pipeline : Tokenizing, AddSpecialTokensWithTruncation, TokenIndexing, \n",
            " ([101, 2002, 2056, 1996, 9440, 2121, 7903, 2063, 11345, 2449, 2987, 1005, 1056, 4906, 1996, 2194, 1005, 1055, 2146, 1011, 2744, 3930, 5656, 1012, 102, 1000, 1996, 9440, 2121, 7903, 2063, 11345, 2449, 2515, 2025, 4906, 2256, 2146, 1011, 2744, 3930, 5656, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1) \n",
            " ([101, 20201, 22948, 2056, 10958, 19053, 4140, 6283, 1996, 8956, 6939, 1998, 2246, 2830, 2000, 2478, 2010, 2146, 2086, 1997, 2731, 1999, 1996, 2162, 1012, 102, 2010, 2564, 2056, 2002, 2001, 1000, 2531, 3867, 2369, 2577, 5747, 1000, 1998, 2246, 2830, 2000, 2478, 2010, 2086, 1997, 2731, 1999, 1996, 2162, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e41IGlDiCeIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = classify.MRPC('mrpc/train.tsv', pipeline)\n",
        "data_iter = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True)\n",
        "\n",
        "model = classify.Classifier(model_cfg, len(classify.MRPC.labels))\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJaAXYjnC6xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3088a366-0735-449d-988f-7dd5d859bc25"
      },
      "source": [
        "save_dir = '.'\n",
        "trainer = train.Trainer(cfg,\n",
        "                        model,\n",
        "                        data_iter,\n",
        "                        optim.optim4GPU(cfg, model),\n",
        "                        save_dir, get_device())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda (1 GPUs)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3dyFC_VCrVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7f06b0e8-373e-49f1-b2c9-128f101d31aa"
      },
      "source": [
        "def get_loss(model, batch, global_step): # make sure loss is a scalar tensor\n",
        "    input_ids, segment_ids, input_mask, label_id = batch\n",
        "    logits = model(input_ids, segment_ids, input_mask)\n",
        "    loss = criterion(logits, label_id)\n",
        "    return loss\n",
        "\n",
        "trainer.train(get_loss, model_file=None, pretrain_file='uncased_L-12_H-768_A-12/bert_model.ckpt', data_parallel=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the pretrained model from uncased_L-12_H-768_A-12/bert_model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter (loss=0.383): 100%|██████████| 115/115 [01:43<00:00,  1.23it/s]\n",
            "Iter (loss=X.XXX):   0%|          | 0/115 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3 : Average Loss 0.556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter (loss=0.324): 100%|██████████| 115/115 [01:45<00:00,  1.23it/s]\n",
            "Iter (loss=X.XXX):   0%|          | 0/115 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/3 : Average Loss 0.273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter (loss=0.062): 100%|██████████| 115/115 [01:45<00:00,  1.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/3 : Average Loss 0.089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gdnQYnyCx1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = classify.MRPC('mrpc/dev.tsv', pipeline)\n",
        "data_iter = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_rofTiTEYON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3486b295-8bf0-4334-edee-8208009d622f"
      },
      "source": [
        "save_dir = '.'\n",
        "trainer = train.Trainer(cfg,\n",
        "                        model,\n",
        "                        data_iter,\n",
        "                        optim.optim4GPU(cfg, model),\n",
        "                        save_dir, get_device())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda (1 GPUs)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYK2kLz3EZWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9bf76d11-e675-4268-aacc-d604aede1075"
      },
      "source": [
        "def evaluate(model, batch):\n",
        "    input_ids, segment_ids, input_mask, label_id = batch\n",
        "    logits = model(input_ids, segment_ids, input_mask)\n",
        "    _, label_pred = logits.max(1)\n",
        "    result = (label_pred == label_id).float() #.cpu().numpy()\n",
        "    accuracy = result.mean()\n",
        "    return accuracy, result\n",
        "\n",
        "results = trainer.eval(evaluate, model_file='model_steps_345.pt', data_parallel=False)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the model from model_steps_345.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter(acc=0.875): 100%|██████████| 13/13 [00:04<00:00,  3.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LabyV_ijEcjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf2e2c57-ed26-44c6-c952-793347005d0e"
      },
      "source": [
        "total_accuracy = torch.cat(results).mean().item()\n",
        "print('Accuracy:', total_accuracy)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8406863212585449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvRft2AdEj7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}